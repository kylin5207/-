{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、如果您在完全相同的训练数据上训练了五个不同的模型，并且它们都达到了95％的精度，那么您是否有可能将这些模型结合起来以获得更好的结果？ 如果是这样，怎么办？ 如果没有，为什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您已经训练了五个不同的模型，并且它们都达到了95％的精度，则可以尝试将它们组合成一个投票集成器，这通常会给您带来更好的结果。如果模型差异很大（例如SVM分类器，决策树分类器，逻辑回归分类器等），则效果更好。如果在不同的训练实例上进行训练（这是bagging和pasting集成的重点），那就更好了，但是如果没有，只要模型非常不同，这仍然有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、硬投票和软投票分类器有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "硬投票分类器仅计算集合中每个分类器的投票，然后选择获得最多投票的类别。软投票分类器计算每个类别的平均估计类别概率，并选择概率最高的类别。 这会给高置信度的投票赋予更大的权重，并且通常会表现更好，但是仅当每个分类器都能够估计分类概率时才有效（例如，对于Scikit-Learn中的SVM分类器，您必须设置probability= True）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、是否可以通过在多台服务器之间分配bagging来加快训练的速度？ pasting集成，boosting集成，随机森林或堆栈集成呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过将bagging集成分布到多个服务器上来加快训练的速度，这是很有可能的，因为集成中的每个预测变量都相互独立。出于相同的原因，pasting集成和随机森林也是如此。但是，boosting集成中的每个预测变量都是基于先前的预测变量构建的，因此训练必须是顺序的，并且通过在多个服务器之间分布训练将不会获得任何收益。关于堆栈集成，给定层中的所有预测变量彼此独立，因此可以在多台服务器上并行训练它们。但是，只有在对上一层中的预测变量进行了全部训练之后，才能对一层中的预测变量进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四、out-of-bag评估的优点："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过out-of-bag，可以使用未经过训练（被排除）的实例评估bagging组合中的每个预测变量。这使得可以对集合进行相当公正的评估，而无需其他验证集。因此，您有更多可用于训练的实例，并且您的集成结果可以稍微好一些。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五、是什么让Extra-trees比常规的随机森林更随机？ 这种额外的随机性如何提供帮助？ Extra-trees是比常规随机森林慢还是快？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在“随机森林”中生长一棵树时，仅考虑特征的随机子集在每个节点处进行拆分。对于Extra-Trees也是如此，但它们又走了一步：与其像常规的决策树一样搜索最佳阈值，不如对每个特征使用随机阈值。这种额外的随机性就像正规化的形式：如果“随机森林”拟合训练数据，则“额外树”可能会表现更好。此外，由于Extra-Trees不会搜索最佳阈值，因此它们的训练速度比Random Forests要快得多。但是，进行预测时，它们既不比随机森林快也不慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "六、如果AdaBoost集合不能拟合训练数据，则应调整哪些超参数以及如何调整？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果AdaBoost集合不能拟合训练数据，则可以尝试增加n_estimators或减少基本估计量的正则化超参数。您也可以尝试稍微提高学习速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "七、如果Gradient Boosting集成对训练集过拟合，您应该增加还是降低学习率？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果Gradient Boosting集成对训练集过拟合，则应尝试降低学习率。您还可以使用提前停止来找到正确数量的n_estimators（可能设置太多）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "八、加载MNIST数据，并将其分为训练集、验证集和测试集（例如，使用1100个实例进行训练，使用300个进行验证，并使用397个进行测试）。然后训练各种分类器，例如随机森林分类器，extra-tree分类器和SVM分类器。接下来，尝试使用软投票或硬投票将它们组合成一个在验证集上胜过每个单独分类器的集合。找到一个后，在测试集上尝试一下。与单个分类器相比，它的性能要好多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现只有1797条数据，每个手写数字图片由8*8个像素点组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 划分数据集，划分为三部分（训练集、验证集和测试集）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先划分训练验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(data, labels, test_size=397, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练验证集划分为训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=300, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 然后训练各种分类器，例如随机森林分类器，extra-tree分类器和SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = LinearSVC(random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False)\n",
      "Training the LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 查看它们在验证集上的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9566666666666667,\n",
       " 0.9733333333333334,\n",
       " 0.9266666666666666,\n",
       " 0.9666666666666667]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现目前最好的是extra-tree分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 接下来，尝试使用软投票或硬投票分类器将它们组合成一个在验证集上胜过它们的集成分类器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"svm_clf\", svm_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_st...\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(100,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_iter=200, momentum=0.9,\n",
       "                                            n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=42,\n",
       "                                            shuffle=True, solver='adam',\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=False, warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9566666666666667,\n",
       " 0.9733333333333334,\n",
       " 0.9266666666666666,\n",
       " 0.9666666666666667]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们删除SVM以查看性能是否有所提高。可以使用set_params（）将估算器设置为None来删除估算器，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_st...\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(100,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_iter=200, momentum=0.9,\n",
       "                                            n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=42,\n",
       "                                            shuffle=True, solver='adam',\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=False, warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.set_params(svm_clf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest_clf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                         warm_start=False)),\n",
       " ('extra_trees_clf',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)),\n",
       " ('svm_clf', None),\n",
       " ('mlp_clf',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "                hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "                n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "                random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "                validation_fraction=0.1, verbose=False, warm_start=False))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                        warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False),\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "           verbose=0),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "               learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "               n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "               random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "               validation_fraction=0.1, verbose=False, warm_start=False)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除svm训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del voting_clf.estimators_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很显然，软投票好一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798488664987406"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9798488664987406, 0.9798488664987406, 0.9773299748110831]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "九、运行上一个练习中的各个分类器，以对验证集进行预测，并使用结果预测创建一个新的训练集：每个训练实例都是一个向量，其中包含来自所有分类器的图像预测集，目标是图片的类别。在这个新的训练集上训练一个分类器，恭喜，您刚刚训练了一个blender，并且与分类器一起构成了一个堆叠合奏！ 现在评估测试集上的整体。 对于测试集中的每幅图像，请使用所有分类器进行预测，然后将预测结果输入到blender中，以获取整体的预测结果。与您之前训练的投票分类器相比如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 生成预测结果的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [9., 9., 9., 9.],\n",
       "       [3., 3., 3., 3.],\n",
       "       ...,\n",
       "       [7., 7., 7., 7.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 创建一个random_forestblender分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=True, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成预测训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rnd_forest_blender.predict(X_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9773299748110831"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，stacking与软投票的效果差不多，都略优于硬投票机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
